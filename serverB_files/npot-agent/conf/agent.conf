###############################################################################
#                            NPOT-AGENT                                       #
###############################################################################

[global_tags]
  cluster = "$NPOT_CLUSTER"

[agent]
  interval = "15s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "5s"
  flush_jitter = "0s"
  precision = ""
  debug = false
  quiet = false
  logfile = "/home1/irteam/npot-agent/logs/npot-agent.log"
  hostname = ""
  omit_hostname = false
  api = "http://npot-dev.navercorp.com"
  tenant = "$NPOT_TENANT"
  cluster = "$NPOT_CLUSTER"

[[outputs.opentsdb]]
  host = "http://npot-dev-tsw.navercorp.com"
  port = 10041
  httpBatchSize = 1024
  tenant = "$NPOT_TENANT"
  debug = false
  dry = false
  filters = []
  httpBatchInterval = "5s"

[[inputs.dfstat]]
  interval = "1m"

[[inputs.ifstat]]

[[inputs.iostat]]

[[inputs.netstat]]

[[inputs.procstats]]
  per_cpu = false

[[inputs.exec]]
    commands = [
        "/home1/irteam/npot-agent/scripts/nginx.py",
##     "/home1/irteam/npot-agent/scripts/kafkalag.sh",
    ]
##   data_format = "tcollector"
   
## [[inputs.mongodb]]
##   servers = [
##     "mongodb://id:pwd@localhost:10011",
##   ]
##   gather_perdb_stats = true
##   df_interval = "1m"

## [[inputs.storm]]
##   server = [
##     "localhost:8080",
##   ]

## [[inputs.redis]]
##  [protocol://][:password]@address[:port]
##    tcp://localhost:6379
##    tcp://:password@192.168.99.100
##    unix:///var/run/redis.sock
##  servers = ["tcp://localhost:6379"]

## [[inputs.zookeeper]]
##   servers = [":2181"]

## [[inputs.hadoop_namenode]]
##   namenode_port = 50070

## [[inputs.hadoop_datanode]]
##   datanode_port = 50075

## [[inputs.hbase_master]]
## #  master_port = 16010
##   master_port = 60010

## [[inputs.hbase_regionserver]]
## #  region_port = 16030
##   region_port = 60030

## [[inputs.haproxy]]
##   servers = ["http://localhost:1936/haproxy?stats"]

## [[inputs.logstash]]
##   servers = ["http://localhost:9600"]

## [[inputs.elasticsearch_tcollector]]
##   ## Compatible with tcollector version of elasticsearch collector
##   servers = ["http://localhost:9200"]
##   http_timeout = "5s"

## [[inputs.elasticsearch]]
##   ## Latest collector with index stats supports
##   ## specify a list of one or more Elasticsearch servers
##   # you can add username and password to your url to use basic authentication:
##   # servers = ["http://user:pass@localhost:9200"]
##   servers = ["http://localhost:9200"]
##
##   ## Timeout for HTTP requests to the elastic search server(s)
##   http_timeout = "5s"
##
##   ## When local is true (the default), the node will read only its own stats.
##   ## Set local to false when you want to read the node stats from all nodes
##   ## of the cluster.
##   local = true
##
##   ## Set cluster_health to true when you want to also obtain cluster health stats
##   cluster_health = false
##
##   ## Adjust cluster_health_level when you want to also obtain detailed health stats.
##   ## The options are
##   ##  - cluster (default)
##   ##  - indices (please let npot team know if you want to use the indices option!!)
##   # cluster_health_level = "cluster"
##
##   ## Set cluster_stats to true when you want to also obtain cluster stats from the
##   ## Master node.
##   cluster_stats = false
##
##   ## node_stats is a list of sub-stats that you want to have gathered. Valid options
##   ## are "indices", "os", "process", "jvm", "thread_pool", "fs", "transport", "http",
##   ## "breakers". Per default, all stats are gathered.
##   # node_stats = ["jvm", "http"]
##
##   ## Optional SSL Config
##   # ssl_ca = "/etc/telegraf/ca.pem"
##   # ssl_cert = "/etc/telegraf/cert.pem"
##   # ssl_key = "/etc/telegraf/key.pem"
##   ## Use SSL but skip chain & host verification
##   # insecure_skip_verify = false
